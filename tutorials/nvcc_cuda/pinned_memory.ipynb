{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44f881a-b276-41cd-8859-847ffb01f6c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe3acb3-4b7a-4dac-bf9d-5810c9f50468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc\n",
    "Image(url='https://developer-blogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg', \n",
    "      width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838db39-f313-4215-b9c3-0e76373d4ca8",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c6fce-af3b-4d24-bb30-4ce658c5713c",
   "metadata": {},
   "source": [
    "- Host (CPU)\n",
    "    - pinned memory 定义在 host（cpu）上；\n",
    "- HtoD: host to device\n",
    "- DtoH: device to host\n",
    "\n",
    "As you can see in the figure, pinned memory is used as a staging area for transfers from the device to the host. We can avoid the cost of the transfer between pageable and pinned host arrays by directly allocating our host arrays in pinned memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba17c53e-adb1-4dde-9cf0-93be234d4d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965acc8-9fcf-4d95-a4b2-4545d3a3fc30",
   "metadata": {},
   "source": [
    "### host to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cce09c8-785f-47b0-a6e6-871f72180d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1719825267791748"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个大的Tensor以便看到明显的时间差异\n",
    "size = (10000, 10000)\n",
    "\n",
    "# 普通内存Tensor\n",
    "normal_tensor = torch.FloatTensor(*size)\n",
    "# 将普通Tensor复制到GPU并计时\n",
    "t0 = time.time()\n",
    "normal_tensor_gpu = normal_tensor.to(\"cuda\")\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8c32e8-b7be-477d-9fae-c01089fb16c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002377033233642578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pinned内存Tensor\n",
    "pinned_tensor = torch.FloatTensor(*size).pin_memory()\n",
    "# 将Pinned Tensor复制到GPU并计时\n",
    "t0 = time.time()\n",
    "pinned_tensor_gpu = pinned_tensor.to(\"cuda\", non_blocking=True)\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf210a7-ea03-4d3a-921c-59a62d5d1df3",
   "metadata": {},
   "source": [
    "### device to host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0570a0db-97b1-43d7-b60b-82e2887457d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3526153564453125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = (10000, 10000)\n",
    "gpu_tensor = torch.randn(*size, device=\"cuda\")\n",
    "\n",
    "# 复制到普通内存并计时\n",
    "t0 = time.time()\n",
    "normal_tensor_cpu = gpu_tensor.to(\"cpu\")\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2c1a088-d6fd-4cb4-958f-5005cd8bb97f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024584054946899414"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为了使用pinned memory，首先在CPU上创建一个pinned memory Tensor\n",
    "pinned_tensor_cpu = torch.randn(*size).pin_memory()\n",
    "\n",
    "# 确保GPU操作完成\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 使用非阻塞方式复制到Pinned内存并计时\n",
    "t0 = time.time()\n",
    "pinned_tensor_cpu.copy_(gpu_tensor, non_blocking=True)\n",
    "torch.cuda.synchronize()  # 等待数据传输完成\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ae04a-b2ab-4ed0-96a2-7aa1eee6cc75",
   "metadata": {},
   "source": [
    "## cuda 编程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dec573-2eb6-4b7a-86b5-bbd85522e8b8",
   "metadata": {},
   "source": [
    "- https://github.com/NVIDIA-developer-blog/code-samples.git\n",
    "    - code-samples/series/cuda-cpp/optimize-data-transfers/bandwidthtest.cu\n",
    "\n",
    "```\n",
    "$ nvcc bandwidthtest.cu -o a.out\n",
    "$ ./a.out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded3232-11cb-4a0a-a047-642b0e37eafd",
   "metadata": {},
   "source": [
    "```\n",
    "Device: NVIDIA GeForce RTX 4090\n",
    "Transfer size (MB): 16\n",
    "\n",
    "Pageable transfers\n",
    "  Host to Device bandwidth (GB/s): 5.959241\n",
    "  Device to Host bandwidth (GB/s): 5.124604\n",
    "\n",
    "Pinned transfers\n",
    "  Host to Device bandwidth (GB/s): 13.453977\n",
    "  Device to Host bandwidth (GB/s): 13.369578\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
